{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn: Build A Pipeline\n",
    "\n",
    "- Combine Your Knowledge of the Website, `requests` and `bs4`\n",
    "- Automate Your Scraping Process Across Multiple Pages\n",
    "- Generalize Your Code For Varying Searches\n",
    "- Target & Save Specific Information You Want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚠️ Durabilty Warning ⚠️\n",
    "\n",
    "Like [mentioned in the course](https://realpython.com/lessons/challenge-of-durability/), websites frequently change. Unfortunately the job board that you'll see in the course, indeed.com, has started to block scraping of their site since the recording of the course.\n",
    "\n",
    "Just like in the associated written tutorial on [web scraping with beautiful soup](https://realpython.com/beautiful-soup-web-scraper-python/#scrape-the-fake-python-job-site), you can instead use [Real Python's fake jobs site](https://realpython.github.io/fake-jobs/) to practice scraping a static website.\n",
    "\n",
    "All the concepts discussed in the course lessons are still accurate. Translating what you see onto a different website will be a good learning opportunity where you'll have to synthesize the information and apply it practically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your Tasks:\n",
    "\n",
    "- Scrape all 100 available job postings\n",
    "- Generalize your code to allow searching for different locations/jobs\n",
    "- Pick out information about the apply URL, job title, and job location\n",
    "- Save the results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Inspect\n",
    "\n",
    "- How do the URLs change when you navigate to a job detail?\n",
    "- Which HTML elements contain the link, title, and location of each job?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Scrape\n",
    "\n",
    "- Build the code to fetch all 100 available job postings.\n",
    "- Write functions that allow you to specify the job title, location, and amount of results as arguments\n",
    "- Also fetch the information provided on each job details page. For this, you'll need to automatically follow URLs that you've fetched when getting the job postings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Parse\n",
    "\n",
    "- Sieve through your HTML soup to pick out only the job title, link, and location from the main page\n",
    "- Sieve through the HTML of each details page to get the job description and combine it with the other information\n",
    "- Format the results in a readable format (e.g. JSON, TXT, TOML, ...)\n",
    "- Save the results to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
